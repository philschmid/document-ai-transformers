{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LayoutLMv1 Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt install -y tesseract-ocr\n",
    "!pip install  pytesseract transformers datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Classification/Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LiltForTokenClassification\n",
    "from transformers import LayoutLMv3FeatureExtractor, AutoTokenizer, LayoutLMv3Processor\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import torch\n",
    "\n",
    "# load model and processor from huggingface hub\n",
    "model = LiltForTokenClassification.from_pretrained(\"philschmid/lilt-en-funsd\")\n",
    "processor = LayoutLMv3Processor.from_pretrained(\"philschmid/lilt-en-funsd\")\n",
    "\n",
    "# helper function to unnormalize bboxes for drawing onto the image\n",
    "def unnormalize_box(bbox, width, height):\n",
    "    return [\n",
    "        width * (bbox[0] / 1000),\n",
    "        height * (bbox[1] / 1000),\n",
    "        width * (bbox[2] / 1000),\n",
    "        height * (bbox[3] / 1000),\n",
    "    ]\n",
    "\n",
    "\n",
    "label2color = {\n",
    "    \"B-HEADER\": \"blue\",\n",
    "    \"B-QUESTION\": \"red\",\n",
    "    \"B-ANSWER\": \"green\",\n",
    "    \"I-HEADER\": \"blue\",\n",
    "    \"I-QUESTION\": \"red\",\n",
    "    \"I-ANSWER\": \"green\",\n",
    "}\n",
    "# draw results onto the image\n",
    "def draw_boxes(image, boxes, predictions):\n",
    "    width, height = image.size\n",
    "    normalizes_boxes = [unnormalize_box(box, width, height) for box in boxes]\n",
    "\n",
    "    # draw predictions over the image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    font = ImageFont.load_default()\n",
    "    for prediction, box in zip(predictions, normalizes_boxes):\n",
    "        if prediction == \"O\":\n",
    "            continue\n",
    "        draw.rectangle(box, outline=\"black\")\n",
    "        draw.rectangle(box, outline=label2color[prediction])\n",
    "        draw.text((box[0] + 10, box[1] - 10), text=prediction, fill=label2color[prediction], font=font)\n",
    "    return image\n",
    "\n",
    "\n",
    "# run inference\n",
    "def run_inference(image, model=model, processor=processor, output_image=True):\n",
    "    # create model input\n",
    "    encoding = processor(image, return_tensors=\"pt\")\n",
    "    del encoding[\"pixel_values\"]\n",
    "    # run inference\n",
    "    outputs = model(**encoding)\n",
    "    predictions = outputs.logits.argmax(-1).squeeze().tolist()\n",
    "    # get labels\n",
    "    labels = [model.config.id2label[prediction] for prediction in predictions]\n",
    "    if output_image:\n",
    "        return draw_boxes(image, encoding[\"bbox\"][0], labels)\n",
    "    else:\n",
    "        return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_inference(\"../assets/invoice_example.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dev': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6dd96c16031089903d5a31ec148b80aeb0d39c32affb1a1080393235fbfa2fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
